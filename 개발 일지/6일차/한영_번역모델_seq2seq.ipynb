{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc260b0-435b-4435-9e9a-f524656debd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1135ff3f-0633-40b2-9449-53e29065a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8765c393-9663-4769-a5f5-5ae8ee932f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_문어체_조례.xlsx',\n",
       " '2_대화체.xlsx',\n",
       " '1_구어체(2).xlsx',\n",
       " '1_구어체(1).xlsx',\n",
       " '3_문어체_뉴스(2).xlsx',\n",
       " '3_문어체_뉴스(3).xlsx',\n",
       " '3_문어체_뉴스(1).xlsx',\n",
       " '4_문어체_한국문화.xlsx',\n",
       " '3_문어체_뉴스(4).xlsx',\n",
       " '6_문어체_지자체웹사이트.xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5215df7-bf25-409f-ae78-7d2fb3203b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>상황</th>\n",
       "      <th>Set Nr.</th>\n",
       "      <th>발화자</th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>A-1</td>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>B-1</td>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>A-2</td>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>1</td>\n",
       "      <td>B-2</td>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비즈니스</td>\n",
       "      <td>회의</td>\n",
       "      <td>의견 교환하기</td>\n",
       "      <td>2</td>\n",
       "      <td>A-1</td>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>여행/쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
       "      <td>24999</td>\n",
       "      <td>B-2</td>\n",
       "      <td>저희가 가격표 배치를 잘못해서 혼동을 드렸나 봐요, 죄송해요.</td>\n",
       "      <td>It seems that we didn't place the price tags c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>여행/쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
       "      <td>25000</td>\n",
       "      <td>A-1</td>\n",
       "      <td>백화점 포인트로 계산하고 싶은데, 가능한가요?</td>\n",
       "      <td>Can I pay using the department store points?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>여행/쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
       "      <td>25000</td>\n",
       "      <td>B-1</td>\n",
       "      <td>네, 물론이죠, 전화번호 입력해주시면 됩니다.</td>\n",
       "      <td>Yes, of course, you just need to enter your ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>여행/쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
       "      <td>25000</td>\n",
       "      <td>A-2</td>\n",
       "      <td>입력했어요, 전액 백화점 포인트로 결제하고 싶어요.</td>\n",
       "      <td>I entered it, I want to pay it with all the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>여행/쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
       "      <td>25000</td>\n",
       "      <td>B-2</td>\n",
       "      <td>죄송하지만 포인트 제외한 차액 15,000원은 따로 결제해주셔야 합니다.</td>\n",
       "      <td>I'm sorry, but you need to make a separate pay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         대분류 소분류                            상황  Set Nr.  발화자  \\\n",
       "0       비즈니스  회의                       의견 교환하기        1  A-1   \n",
       "1       비즈니스  회의                       의견 교환하기        1  B-1   \n",
       "2       비즈니스  회의                       의견 교환하기        1  A-2   \n",
       "3       비즈니스  회의                       의견 교환하기        1  B-2   \n",
       "4       비즈니스  회의                       의견 교환하기        2  A-1   \n",
       "...      ...  ..                           ...      ...  ...   \n",
       "99995  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    24999  B-2   \n",
       "99996  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  A-1   \n",
       "99997  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  B-1   \n",
       "99998  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  A-2   \n",
       "99999  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  B-2   \n",
       "\n",
       "                                             원문  \\\n",
       "0                   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1                    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2                  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3                   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4                   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "...                                         ...   \n",
       "99995        저희가 가격표 배치를 잘못해서 혼동을 드렸나 봐요, 죄송해요.   \n",
       "99996                 백화점 포인트로 계산하고 싶은데, 가능한가요?   \n",
       "99997                 네, 물론이죠, 전화번호 입력해주시면 됩니다.   \n",
       "99998              입력했어요, 전액 백화점 포인트로 결제하고 싶어요.   \n",
       "99999  죄송하지만 포인트 제외한 차액 15,000원은 따로 결제해주셔야 합니다.   \n",
       "\n",
       "                                                     번역문  \n",
       "0      How is the market's reaction to the newly rele...  \n",
       "1      The sales increase is faster than the previous...  \n",
       "2      Then, we'll have to call the manufacturer and ...  \n",
       "3      Sure, I'll make a call and double the volume o...  \n",
       "4      Shall we take a look at the issues we discusse...  \n",
       "...                                                  ...  \n",
       "99995  It seems that we didn't place the price tags c...  \n",
       "99996       Can I pay using the department store points?  \n",
       "99997  Yes, of course, you just need to enter your ph...  \n",
       "99998  I entered it, I want to pay it with all the de...  \n",
       "99999  I'm sorry, but you need to make a separate pay...  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('2_대화체.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a79bee2-0239-4c73-b037-de3c266c7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['원문','번역문'])\n",
    "\n",
    "file_list = [ '2_대화체.xlsx',\n",
    " '1_구어체(2).xlsx',\n",
    " '1_구어체(1).xlsx',\n",
    " '3_문어체_뉴스(2).xlsx',\n",
    " '3_문어체_뉴스(3).xlsx',\n",
    " '3_문어체_뉴스(1).xlsx',\n",
    " '4_문어체_한국문화.xlsx',\n",
    " '3_문어체_뉴스(4).xlsx']\n",
    "\n",
    "for data in file_list:\n",
    "    temp = pd.read_excel(data)\n",
    "    df = pd.concat([df,temp[['원문','번역문']]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b4b042-a3c2-46fc-8f02-459455b1f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             원문  \\\n",
       "0   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                 번역문  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ac813d-f68f-42ae-a9a5-eb55247877da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc9599-ce97-4203-83e2-3d4d87daf630",
   "metadata": {},
   "source": [
    "## 토크나이저 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2886e8-b3ac-4fd8-b90a-af24ba341933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data \n",
    "from konlpy.tag import Okt\n",
    "\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032bda3a-6290-4494-ab74-2bae9436fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_kor(text):\n",
    "    \"\"\"한국어를 tokenizer해서 단어들을 리스트로 만든 후 reverse\"\"\"\n",
    "    return [text_ for text_ in tokenizer.morphs(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"영어를 split tokenizer해서 단어들을 리스트로 만듦\"\"\"\n",
    "    return [text_ for text_ in text.split()]\n",
    "\n",
    "# 필드 정의\n",
    "\n",
    "SRC = data.Field(tokenize = tokenize_kor,\n",
    "                init_token = '<sos>',\n",
    "                eos_token = '<eos>')\n",
    "\n",
    "TRG = data.Field(tokenize = tokenize_en,\n",
    "                init_token = '<sos>',\n",
    "                eos_token = '<eos>',\n",
    "                lower = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fd3f9-80df-401a-a538-e97753cf764f",
   "metadata": {},
   "source": [
    "# 데이터셋 만들기 (전체 데이터중 100,000개만 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9a9a9c-e0fd-45df-a17b-bf0604402ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>복무기간 단축안은 10월 전역자부터 2주 단위로 하루씩 단축해 육군·해병대·의무경찰...</td>\n",
       "      <td>The proposed reduction of the service period w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>실제로 이번 인사에서 인천지검 특수부장, 서울중앙지검 증권범죄합동수사단장 등을 지낸...</td>\n",
       "      <td>In fact, the vice chief of the Seoul Eastern D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>29일 서울 서초구 한국산업기술진흥협회 중회의실에서 열린 ‘이공계 우수인재 양성 및...</td>\n",
       "      <td>On the 29th, at a meeting of experts on \"how t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>광주시교육청은 “지난 1일과 2일 한유총 광주지회로부터 장휘국 교육감 면담 요청이 ...</td>\n",
       "      <td>The Gwangju Office of Education said, “There w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>과학기술정보통신부 과학기술혁신본부장에는 김성수(58) 한국화학연구원장, 행정안전부 ...</td>\n",
       "      <td>The appointment for the head of the Science an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1402033 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       원문  \\\n",
       "0                             이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1                              판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2                            그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3                             네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4                             지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "...                                                   ...   \n",
       "199995  복무기간 단축안은 10월 전역자부터 2주 단위로 하루씩 단축해 육군·해병대·의무경찰...   \n",
       "199996  실제로 이번 인사에서 인천지검 특수부장, 서울중앙지검 증권범죄합동수사단장 등을 지낸...   \n",
       "199997  29일 서울 서초구 한국산업기술진흥협회 중회의실에서 열린 ‘이공계 우수인재 양성 및...   \n",
       "199998  광주시교육청은 “지난 1일과 2일 한유총 광주지회로부터 장휘국 교육감 면담 요청이 ...   \n",
       "199999  과학기술정보통신부 과학기술혁신본부장에는 김성수(58) 한국화학연구원장, 행정안전부 ...   \n",
       "\n",
       "                                                      번역문  \n",
       "0       How is the market's reaction to the newly rele...  \n",
       "1       The sales increase is faster than the previous...  \n",
       "2       Then, we'll have to call the manufacturer and ...  \n",
       "3       Sure, I'll make a call and double the volume o...  \n",
       "4       Shall we take a look at the issues we discusse...  \n",
       "...                                                   ...  \n",
       "199995  The proposed reduction of the service period w...  \n",
       "199996  In fact, the vice chief of the Seoul Eastern D...  \n",
       "199997  On the 29th, at a meeting of experts on \"how t...  \n",
       "199998  The Gwangju Office of Education said, “There w...  \n",
       "199999  The appointment for the head of the Science an...  \n",
       "\n",
       "[1402033 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1cb7c9-acd2-4981-982d-83a8db00e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled=df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c3b2813-ba82-4ec0-aec8-c505a34ca548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "df_ = df_shuffled[:100000]\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "for i,(trn_idx,val_idx) in enumerate(kf.split(df_['원문'])):\n",
    "    trn = df_.iloc[trn_idx]\n",
    "    val = df_.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f5e100-feb0-4c26-add1-6336de08650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn size:  80000\n",
      "val size:  20000\n"
     ]
    }
   ],
   "source": [
    "print('trn size: ',len(trn))\n",
    "print('val size: ',len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2371daea-fde2-407a-87b1-562892550a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.to_csv('trn.csv',index = False)\n",
    "val.to_csv('val.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed49ada2-6237-4bd7-b272-0b168b2e5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "train_data, validation_data =TabularDataset.splits(\n",
    "     path='', train='trn.csv',validation= 'val.csv', format='csv',\n",
    "        fields=[('원문', SRC), ('번역문', TRG)], skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9c563-1359-4857-b690-6abd8d0c02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('검증 샘플의 개수 : {}'.format(len(validation_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d92723-dac7-4039-b4af-6e59bee08ce7",
   "metadata": {},
   "source": [
    "### Vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da03d22-a061-48ef-afed-b42547c40b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2, max_size = 50000)\n",
    "TRG.build_vocab(train_data, min_freq = 2, max_size = 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399fc750-ed35-42c2-affb-033362107b5c",
   "metadata": {},
   "source": [
    "### data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990da331-86c0-4cf5-8176-c341b7f828db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Iterator\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "train_loader = Iterator(dataset = train_data, batch_size = batch_size)\n",
    "val_loader = Iterator(dataset = validation_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25841fd0-0f7e-4879-b935-eb5e11131cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 625\n",
      "검증 데이터의 미니 배치 수 : 157\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('검증 데이터의 미니 배치 수 : {}'.format(len(val_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e43da6d-d003-4d0e-853f-1db16634fe0d",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0674797-e48d-46cd-8440-4f327140911c",
   "metadata": {},
   "source": [
    "### encoder\n",
    "- 2 layer RNN\n",
    "- Layer 1: 독일어 토큰의 임베딩을 입력으로 받고 은닉상태 출력\n",
    "- Layer 2 : Layer1의 은닉상태를 입력으로 받고 새로운 은닉상태 출력\n",
    "- 각 layer마다 초기 은닉상태 h_0 필요 (0으로 초기화 ?)\n",
    "- 각 layer마다 context vector 'z'를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825bbc09-3dbd-41ab-ad54-b1a6fefdd691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder \n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"seq2seq의 encoder\n",
    "\n",
    "\n",
    "    input_dim : input 데이터의 vocab size \n",
    "    단어들의 index가 embedding 함수로 넘겨짐\n",
    "\n",
    "    emb_dim : embedding layer의 차원\n",
    "    embedding 함수 : one-hot vector를 emb_dim 길이의 dense vector로 변환\n",
    "\n",
    "    hid_dim : 은닉 상태의 차원 ( = cell state의 차원)\n",
    "\n",
    "    n_layers : RNN 안의 레이어 개수 (여기선 2개)\n",
    "\n",
    "    dropout : 사용할 드롭아웃의 양 (오버피팅 방지하는 정규화 방법)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU( emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch_size)]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embeded = [src len, batch size, emb dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        \n",
    "        return hidden\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892935a1-1002-47a8-bc20-24fdb649878c",
   "metadata": {},
   "source": [
    "### decoder\n",
    "- Layer 1 : 직전 time-stamp로 부터 은닉 상태(s)와 cell state를 받고, 이들과 embedded token인 y_t를 입력으로 받아 새로운 은닉상태와 cell state를 만들어냄\n",
    "- Layer 2 : Layer 2의 은닉 상태(s)와 Layer 2에서 직전 time-stamp의 은닉 상태(s)와 cell state를 입력으로 받아 새로운 은닉 상태와 cell state를 만들어냄\n",
    "- Decoder Layer1의 `첫 은닉상태(s)와 cell state` = `context vector (z)` = `Encoder Layer 1의 마지막 은닉상태(h)와 cell state`\n",
    "- Decoder RNN/LSTM의 맨 위 Layer의 은닉 상태를 Linear Layer인 f에 넘겨서 다음 토큰이 무엇일지 예측함\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42f57bf2-a22f-4a98-be62-1bc6160dda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) : \n",
    "    \"\"\"seq2seq의 decoder\n",
    "\n",
    "\n",
    "    input_dim : input 데이터의 vocab size \n",
    "    단어들의 index가 embedding 함수로 넘겨짐\n",
    "\n",
    "    emb_dim : embedding layer의 차원\n",
    "    embedding 함수 : one-hot vector를 emb_dim 길이의 dense vector로 변환\n",
    "\n",
    "    hid_dim : 은닉 상태의 차원 ( = cell state의 차원)\n",
    "\n",
    "    n_layers : RNN 안의 레이어 개수 (여기선 2개)\n",
    "\n",
    "    dropout : 사용할 드롭아웃의 양 (오버피팅 방지하는 정규화 방법)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        # Decoder에서 항상 n directions = 1\n",
    "        # 따라서 hidden = [n layers, batch size, hid dim]\n",
    "        # context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # input = [1, batch size]\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        # embedded = [1, batch size, emb dim]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        \n",
    "        # output = [seq len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        # Decoder에서 항상 seq len = n directions = 1 \n",
    "        # 한 번에 한 토큰씩만 디코딩하므로 seq len = 1\n",
    "        # 따라서 output = [1, batch size, hid dim]\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        # cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # prediction = [batch size, output dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return prediction, hidden\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1692796b-0556-46eb-b3ca-0cf7004e936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        # Encoder와 Decoder의 hidden dim이 같아야 함 \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \"encoder와 decoder의 hidden dim이 다름.\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"encoder와 decoder의 n_layers이 다름.\"\n",
    "\n",
    "    def forward(self, src, trg ,teacher_forcing_ratio = 0.5):\n",
    "\n",
    "        # src = [src len, batch size]\n",
    "        # trg = [trg len, batch size]\n",
    "\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # decoder 결과를 저장할 텐서\n",
    "        outputs = torch.zeros([trg_len,batch_size , trg_vocab_size])\n",
    "\n",
    "        # encoder의 마지막 은닉 상태가 Deocder의 초기 은닉상태로 쓰임\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        # decoder에 들어갈 첫 input은 <sos>토큰\n",
    "        input = trg[0,:]\n",
    "\n",
    "        #target length만큼 반복\n",
    "        # range(0,trg_len)이 아니라 range(1,trg_len)인 이유 : 0번째 trg는 항상 <sos>라서 그에 대한 output도 항상 0 \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # 확률 가장 높게 예측한 토큰\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            #teacher_force = 1 = true 면 trg[t]를 아니면 top1을 input으로 사용\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dd0b81a-c031-4d5e-92f5-8c80eda004c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a9121c0-d7f3-4793-80f4-177ee11ba278",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(SRC.vocab)\n",
    "output_dim = len(TRG.vocab)\n",
    "\n",
    "# Encoder embedding dim\n",
    "enc_emb_dim = 256\n",
    "# Decoder embedding dim\n",
    "dec_emb_dim = 256\n",
    "\n",
    "hid_dim=512\n",
    "n_layers=2\n",
    "\n",
    "enc_dropout = 0.5\n",
    "dec_dropout=0.5\n",
    "\n",
    "enc = Encoder(input_dim, enc_emb_dim, hid_dim, n_layers, enc_dropout)\n",
    "dec = Decoder(output_dim, dec_emb_dim, hid_dim, n_layers, dec_dropout)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c054152c-54ff-4df3-bdf0-67e740f1b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# <pad> 토큰의 index를 넘겨 받으면 오차 계산하지 않고 ignore하기\n",
    "# <pad> = padding\n",
    "trg_pad_idx = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = trg_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49bc3b46-1893-434c-8c65-81ee4b66df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss=0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.원문.to(device)\n",
    "        trg = batch.번역문.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # trg = [trg len, batch size]\n",
    "        # output = [trg len, batch size, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # loss 함수는 2d input으로만 계산 가능 \n",
    "        output = output[1:].view(-1, output_dim).to(device)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # trg = [(trg len-1) * batch size]\n",
    "        # output = [(trg len-1) * batch size, output dim)]\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # 기울기 폭발 막기 위해 clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss+=loss.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ddeda37-317e-4799-b3a9-9116ef5c600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.원문.to(device)\n",
    "            trg = batch.번역문.to(device)\n",
    "            \n",
    "            # teacher_forcing_ratio = 0 (아무것도 알려주면 안 됨)\n",
    "            output = model(src, trg, 0)\n",
    "            \n",
    "            # trg = [trg len, batch size]\n",
    "            # output = [trg len, batch size, output dim]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim).to(device)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            # trg = [(trg len - 1) * batch size]\n",
    "            # output = [(trg len - 1) * batch size, output dim]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss+=loss.item()\n",
    "        \n",
    "        return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c35f097d-f641-4a6e-84db-8441429b350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count training time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7adb0c7-f1f6-4b6d-8e77-1a3e08c1b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 92m 8s\n",
      "\tTrain Loss: 7.001 | Train PPL: 1097.763\n",
      "\t Val. Loss: 6.758 |  Val. PPL: 860.662\n",
      "Epoch: 02 | Time: 91m 49s\n",
      "\tTrain Loss: 6.448 | Train PPL: 631.544\n",
      "\t Val. Loss: 6.604 |  Val. PPL: 737.715\n",
      "Epoch: 03 | Time: 91m 46s\n",
      "\tTrain Loss: 6.159 | Train PPL: 472.787\n",
      "\t Val. Loss: 6.506 |  Val. PPL: 669.069\n",
      "Epoch: 04 | Time: 92m 2s\n",
      "\tTrain Loss: 5.947 | Train PPL: 382.529\n",
      "\t Val. Loss: 6.448 |  Val. PPL: 631.391\n",
      "Epoch: 05 | Time: 92m 4s\n",
      "\tTrain Loss: 5.772 | Train PPL: 321.065\n",
      "\t Val. Loss: 6.406 |  Val. PPL: 605.700\n",
      "Epoch: 06 | Time: 92m 4s\n",
      "\tTrain Loss: 5.617 | Train PPL: 274.975\n",
      "\t Val. Loss: 6.392 |  Val. PPL: 597.030\n",
      "Epoch: 07 | Time: 92m 19s\n",
      "\tTrain Loss: 5.489 | Train PPL: 242.084\n",
      "\t Val. Loss: 6.401 |  Val. PPL: 602.354\n",
      "Epoch: 08 | Time: 92m 22s\n",
      "\tTrain Loss: 5.358 | Train PPL: 212.199\n",
      "\t Val. Loss: 6.385 |  Val. PPL: 592.977\n",
      "Epoch: 09 | Time: 92m 39s\n",
      "\tTrain Loss: 5.254 | Train PPL: 191.396\n",
      "\t Val. Loss: 6.417 |  Val. PPL: 612.416\n",
      "Epoch: 10 | Time: 93m 57s\n",
      "\tTrain Loss: 5.154 | Train PPL: 173.150\n",
      "\t Val. Loss: 6.430 |  Val. PPL: 620.039\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c709c570-fe4f-4509-865a-f06cf131c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역(translation) 함수\n",
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
    "    \"\"\"\n",
    "    문장을 받아 번역 해주는 함수.\n",
    "    \"\"\"\n",
    "    model.eval() # 평가 모드\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [text_ for text_ in tokenizer.morphs(sentence)][::-1]\n",
    "    else:\n",
    "        raise Exception(\"input 데이터가 str이 아닙니다.\")\n",
    "        \n",
    "\n",
    "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    print(f\"전체 소스 토큰: {tokens}\")\n",
    "\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    print(f\"소스 문장 인덱스: {src_indexes}\")\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "\n",
    "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        # 이전에 출력한 단어가 현재 단어로 입력될 수 있도록\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        # <eos>를 만나는 순간 끝\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
    "\n",
    "        \n",
    "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "\n",
    "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2179ebea-105b-45d6-a703-4034db683618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<sos>', '으로', '집', '가고싶다', '는', '나', '<eos>']\n",
      "소스 문장 인덱스: [2, 14, 209, 0, 13, 48, 3]\n",
      "[2, 16, 71, 6, 116, 1582]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'to', 'go', 'home.']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '나는 가고싶다 집으로'\n",
    "\n",
    "translate_sentence(sentence, SRC, TRG, model, device, max_len=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdg",
   "language": "python",
   "name": "bdg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
