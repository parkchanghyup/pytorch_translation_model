{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b585d8-ca5c-47be-b84a-343b3927b8f2",
   "metadata": {},
   "source": [
    "# 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78498ab0-0dc3-4431-9eb4-478c7df9e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a14d971-b65d-49af-ae7e-1f43c126a902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_문어체_조례.xlsx',\n",
       " '2_대화체.xlsx',\n",
       " '1_구어체(2).xlsx',\n",
       " '1_구어체(1).xlsx',\n",
       " '3_문어체_뉴스(2).xlsx',\n",
       " '3_문어체_뉴스(3).xlsx',\n",
       " '3_문어체_뉴스(1).xlsx',\n",
       " '4_문어체_한국문화.xlsx',\n",
       " '3_문어체_뉴스(4).xlsx',\n",
       " '6_문어체_지자체웹사이트.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = glob('*.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26aa0c1-3118-4bc6-aa06-fe039723073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 문어체_조레, 문어제_지자체웝사이트 파일 제외하고 데이터 프레임 생성\n",
    "\n",
    "df = pd.DataFrame(columns = ['원문','번역문'])\n",
    "\n",
    "file_list = [ '2_대화체.xlsx',\n",
    " '1_구어체(2).xlsx',\n",
    " '1_구어체(1).xlsx',\n",
    " '3_문어체_뉴스(2).xlsx',\n",
    " '3_문어체_뉴스(3).xlsx',\n",
    " '3_문어체_뉴스(1).xlsx',\n",
    " '4_문어체_한국문화.xlsx',\n",
    " '3_문어체_뉴스(4).xlsx']\n",
    "\n",
    "for data in file_list:\n",
    "    temp = pd.read_excel(data)\n",
    "    df = pd.concat([df,temp[['원문','번역문']]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaddd83-dd8e-41a3-b88f-bdbab15dc414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>원문</th>\n",
       "      <th>번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
       "      <td>How is the market's reaction to the newly rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
       "      <td>The sales increase is faster than the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
       "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
       "      <td>Sure, I'll make a call and double the volume o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
       "      <td>Shall we take a look at the issues we discusse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             원문  \\\n",
       "0   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
       "1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
       "2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
       "3   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
       "4   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
       "\n",
       "                                                 번역문  \n",
       "0  How is the market's reaction to the newly rele...  \n",
       "1  The sales increase is faster than the previous...  \n",
       "2  Then, we'll have to call the manufacturer and ...  \n",
       "3  Sure, I'll make a call and double the volume o...  \n",
       "4  Shall we take a look at the issues we discusse...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff3efbd-5844-4d0a-bc56-faba50c3a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045fb7b-3ed6-4148-9ed4-9993d3c1bd4b",
   "metadata": {},
   "source": [
    "# 토크나이저 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743055ef-e297-455b-b609-2e9bed15d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data \n",
    "from konlpy.tag import Okt\n",
    "\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663d8c95-8647-4035-b617-1c90bb90a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_kor(text):\n",
    "    \"\"\"\n",
    "    한국어를 tokenizer해서 단어들을 리스트로 만든 후 reverse하여 반환\n",
    "    \"\"\"\n",
    "    return [text_ for text_ in tokenizer.morphs(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    영어를 split tokenizer해서 단어들을 리스트로 만드는 함수\n",
    "    \n",
    "    \"\"\"\n",
    "    return [text_ for text_ in text.split()]\n",
    "\n",
    "# 필드 정의\n",
    "\n",
    "SRC = data.Field(tokenize = tokenize_kor,\n",
    "                init_token = '<sos>',\n",
    "                eos_token = '<eos>')\n",
    "\n",
    "TRG = data.Field(tokenize = tokenize_en,\n",
    "                init_token = '<sos>',\n",
    "                eos_token = '<eos>',\n",
    "                lower = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273783fa-0b48-4efb-8620-b65251557925",
   "metadata": {},
   "source": [
    "# 데이터셋 만들기 (전체 데이터중 10만개만 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8953e150-aaf8-40f8-94d7-8df8ebc22766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled=df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "319d1c98-643a-4295-a1d2-d074d696af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# 우선 전제 데이터중 10만개만 사용\n",
    "df_ = df_shuffled[:100000]\n",
    "\n",
    "train_df = df_[:95000]\n",
    "test_df = df_[95000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "67f10bef-b00b-43ad-88af-a9736b8abdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn size:  95000\n",
      "test size:  5000\n"
     ]
    }
   ],
   "source": [
    "print('trn size: ',len(train_df))\n",
    "print('test size: ',len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c84dcb9f-a845-479e-afd8-75e1b60b975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv',index = False)\n",
    "test_df.to_csv('test_df.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f60e15e6-3a48-4939-804e-183629f09d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train_data, test_data =TabularDataset.splits(\n",
    "     path='', train='train_df.csv',test= 'test_df.csv', format='csv',\n",
    "        fields=[('원문', SRC), ('번역문', TRG)], skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "423aea54-e7f8-4046-8886-d4ac4b43a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 검증데이터셋 분리\n",
    "train_data, validation_data = train_data.split(split_ratio = 0.8, random_state = random.seed(323))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9bc8e8d5-38fa-4b3e-a8f2-7a1db477084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 76000\n",
      "검증 샘플의 개수 : 19000\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('검증 샘플의 개수 : {}'.format(len(validation_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ae097-1ae0-4ae2-bcea-4c39e3242ba8",
   "metadata": {},
   "source": [
    "# Vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "624ebff3-0176-491a-8bee-ff2536cad8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 말뭉치 생성\n",
    "SRC.build_vocab(train_data, min_freq = 2, max_size = 50000)\n",
    "TRG.build_vocab(train_data, min_freq = 2, max_size = 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457cd26-1dfd-41a1-b90a-a496a16bc69c",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1b79ec62-c588-4e11-8ca3-5e425c61c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader 생성\n",
    "from torchtext.data import Iterator\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "train_iterator = Iterator(dataset = train_data, batch_size = batch_size)\n",
    "valid_iterator = Iterator(dataset = validation_data, batch_size = batch_size)\n",
    "test_iterator  = Iterator(dataset = test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2a1d1b98-de0e-413a-8815-fb5975a30e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치 수 : 594\n",
      "검증 데이터의 미니 배치 수 : 149\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_iterator)))\n",
    "print('검증 데이터의 미니 배치 수 : {}'.format(len(valid_iterator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6499cd2-7c08-459b-b188-93fd9aea9442",
   "metadata": {},
   "source": [
    "# 모델 설계\n",
    "## encoder\n",
    "- 2 layer RNN\n",
    "- back-bone으로 GRU 사용\n",
    "- Layer 1: 독일어 토큰의 임베딩을 입력으로 받고 은닉상태 출력\n",
    "- Layer 2 : Layer1의 은닉상태를 입력으로 받고 새로운 은닉상태 출력\n",
    "- 각 layer마다 초기 은닉상태 h|_0 필요 (0으로 초기화 ?)\n",
    "- 각 layer마다 context vector 'z'를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a1935f5b-362d-4ff7-99b5-089d29b7f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    seq2seq의 encoder\n",
    "    \n",
    "    attribute\n",
    "    ---\n",
    "    input_dim : int\n",
    "        input 데이터의 차원(= vocab size)\n",
    "    emb_dim : int\n",
    "        embedding layer의 차원\n",
    "    hid_dim : int\n",
    "        은닉 상태의 차원\n",
    "    n_layers : int\n",
    "        RNN 안의 레이어 개수 (여기선 2개)\n",
    "    dropout : float\n",
    "        사용할 드롭아웃의 비율 (오버피팅 방지하는 정규화 방법)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout = 0.2):\n",
    "       \n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        \n",
    "        파라미터 \n",
    "        ---\n",
    "        src : [src len, batch_size)]\n",
    "            input data\n",
    "        return\n",
    "        ---\n",
    "        hidden : [[n layers * n directions, batch size, hid dim]]\n",
    "            encoder의 hidden state. decoder의 입력으로 사용됨\n",
    "        \"\"\"\n",
    "        #src = [src len, batch_size)]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embeded = [src len, batch size, emb dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81685929-7d3f-4f01-9457-188c44d567d1",
   "metadata": {},
   "source": [
    "## decoder\n",
    "- Layer 1 : 직전 time-stamp로 부터 은닉 상태(s)와 cell state를 받고, 이들과 embedded token인 y_t를 입력으로 받아 새로운 은닉상태와 cell state를 만들어냄\n",
    "- Layer 2 : Layer 2의 은닉 상태(s)와 Layer 2에서 직전 time-stamp의 은닉 상태(s)와 cell state를 입력으로 받아 새로운 은닉 상태와 cell state를 만들어냄\n",
    "- Decoder Layer1의 첫 은닉상태(s)와 cell state = context vector (z) = Encoder Layer 1의 마지막 은닉상태(h)와 cell state\n",
    "- Decoder RNN/LSTM의 맨 위 Layer의 은닉 상태를 Linear Layer인 f에 넘겨서 다음 토큰이 무엇일지 예측함\n",
    "- 여기서는 GRU를 사용했기 때문에 cell state는 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fb88b35b-148f-472a-892e-ca6d2957083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) : \n",
    "    \"\"\"\n",
    "    seq2seq의 Decoder\n",
    "    \n",
    "    attribute\n",
    "    ---\n",
    "    output_dim : int\n",
    "        출력 될 데이터의 차원, 타겟 데이터의 임베딩 차원        \n",
    "    emb_dim  : int\n",
    "        embedding layer의 차원\n",
    "    hid_dim : int\n",
    "        은닉 상태의 차원\n",
    "    n_layers : int\n",
    "        RNN 안의 레이어 개수 (여기선 2개)\n",
    "    dropout : float\n",
    "        사용할 드롭아웃의 비율 (오버피팅 방지하는 정규화 방법)\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"\n",
    "\n",
    "        파라미터\n",
    "        ---\n",
    "        input: [batch size]\n",
    "            이전 단어\n",
    "        hidden : [n layers * n directions, batch size, hid dim]\n",
    "            이전 layer의 hidden state\n",
    "            \n",
    "        returns\n",
    "        ---\n",
    "        prediction : torch.tensor\n",
    "            현재 sequence에서 생성된 출력 벡터(단어)\n",
    "        hidden : [n layers, batch size, hid dim]\n",
    "            decoder의 hidden state. 다음 decoder로 전달됨.\n",
    "        \"\"\"\n",
    "\n",
    "        # \n",
    "        # \n",
    "        # Decoder에서 항상 n directions = 1\n",
    "        # 따라서 hidden = [n layers, batch size, hid dim]\n",
    "        # context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # input = [1, batch size]\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        # embedded = [1, batch size, emb dim]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        \n",
    "        # output = [seq len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    " \n",
    "        # Decoder에서 항상 seq len = n directions = 1 \n",
    "        # 한 번에 한 토큰씩만 디코딩하므로 seq len = 1\n",
    "        # 따라서 output = [1, batch size, hid dim]\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # prediction = [batch size, output dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return prediction, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bd9e9aa1-6f60-4115-a088-a5777761d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    encoder와 decoder를 이용해 seq2seq 모델을 설계하는 class\n",
    "    \n",
    "    attribute\n",
    "    ---\n",
    "    encoder : \n",
    "        encoder 클래스\n",
    "    decoder :\n",
    "        decoder 클래스\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "\n",
    "        # Encoder와 Decoder의 hidden dim이 같아야 함 \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \"encoder와 decoder의 hidden dim이 다름.\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"encoder와 decoder의 n_layers이 다름.\"\n",
    "\n",
    "    def forward(self, src, trg ,teacher_forcing_ratio = 0.5):\n",
    "        \"\"\" \n",
    "        seq2seq 모델을 통해 예측 값 생성\n",
    "\n",
    "        파라미터\n",
    "        ---\n",
    "        src : [src len, batch size]\n",
    "            input 데이터의 임베딩 차원\n",
    "        trg : [trg len, batch size]\n",
    "            target 데이터의 임베딩 차원\n",
    "        teacher_forcing_ration : float\n",
    "            teacher forcing의 비율\n",
    "        \n",
    "        returns\n",
    "        ---\n",
    "        outputs : [trg len, batch size, output dim]\n",
    "            seq2seq를 통해 생성된 단어의 벡터 \n",
    "        \"\"\"\n",
    "\n",
    "        # \n",
    "        # trg = [trg len, batch size]\n",
    "\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # decoder 결과를 저장할 텐서\n",
    "        outputs = torch.zeros([trg_len,batch_size , trg_vocab_size])\n",
    "\n",
    "        # encoder의 마지막 은닉 상태가 Deocder의 초기 은닉상태로 쓰임\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        # decoder에 들어갈 첫 input은 <sos>토큰\n",
    "        input = trg[0,:]\n",
    "\n",
    "        # target length만큼 반복\n",
    "        # range(0,trg_len)이 아니라 range(1,trg_len)인 이유 : 0번째 trg는 항상 <sos>라서 그에 대한 output도 항상 0\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # 확률 가장 높게 예측한 토큰\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            #teacher_force = 1 = true 면 trg[t]를 아니면 top1을 input으로 사용\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3a025da9-1eaa-4275-937a-f5e7ed8463eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(SRC.vocab)\n",
    "output_dim = len(TRG.vocab)\n",
    "\n",
    "# Encoder embedding dim \n",
    "enc_emb_dim = 256\n",
    "\n",
    "# Decoder embedding dim \n",
    "dec_emb_dim = 256\n",
    "\n",
    "hid_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "# 인코더 디코더 설정\n",
    "enc = Encoder(input_dim, enc_emb_dim, hid_dim, n_layers,enc_dropout)\n",
    "dec = Decoder(output_dim, dec_emb_dim, hid_dim, n_layers,dec_dropout)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model = Seq2Seq(enc, dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "026288ef-a0f9-4bf8-b53a-cb96ddfff60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    가중치 초기화\n",
    "    \"\"\"\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "model = model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f4f59-ae3b-4282-a1b7-645fe51ec5f2",
   "metadata": {},
   "source": [
    "## Optimizer / Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b528efe-29b9-4024-bb69-b05a5f72db96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# <pad> 토큰의 index를 넘겨 받으면 오차를 계산하지 않고 ignore하기\n",
    "# <pad> = padding\n",
    "trg_pad_idx = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = trg_pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6af8d-000b-45a0-b886-57e81c4af878",
   "metadata": {},
   "source": [
    "## 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c8c6d03d-bdc3-4d33-81e7-4afea2ee7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \"\"\"\n",
    "    모델을 학습하는 코드\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss=0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.원문.to(device) # [25,128]\n",
    "        trg = batch.번역문.to(device) # [29,128]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg).to(device)\n",
    "        \n",
    "        # trg = [trg len, batch size]\n",
    "        # output = [trg len, batch size, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # loss 함수는 2d input으로만 계산 가능 \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # trg = [(trg len-1) * batch size]\n",
    "        # output = [(trg len-1) * batch size, output dim)]\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # 기울기 폭발 막기 위해 clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss+=loss.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "40ef56c0-5058-4a11-8d19-687c82bee80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \"\"\"\n",
    "    학습된 모델을 평가하는 코드\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.원문.to(device)\n",
    "            trg = batch.번역문.to(device)\n",
    "            \n",
    "            # teacher_forcing_ratio = 0 (아무것도 알려주면 안 됨)\n",
    "            output = model(src, trg, 0).to(device)\n",
    "            \n",
    "            # trg = [trg len, batch size]\n",
    "            # output = [trg len, batch size, output dim]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            # trg = [(trg len - 1) * batch size]\n",
    "            # output = [(trg len - 1) * batch size, output dim]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss+=loss.item()\n",
    "        \n",
    "        return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "47ec4848-f69b-469f-aa0b-79de8290e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count training time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27868d34-a55a-4e12-8372-2e7bc8908e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 128m 33s\n",
      "\tTrain Loss: 6.758 | Train PPL: 860.864\n",
      "\t Val. Loss: 6.595 |  Val. PPL: 731.301\n",
      "Epoch: 02 | Time: 130m 10s\n",
      "\tTrain Loss: 6.043 | Train PPL: 421.068\n",
      "\t Val. Loss: 6.421 |  Val. PPL: 614.908\n",
      "Epoch: 03 | Time: 130m 9s\n",
      "\tTrain Loss: 5.689 | Train PPL: 295.719\n",
      "\t Val. Loss: 6.290 |  Val. PPL: 539.014\n",
      "Epoch: 04 | Time: 129m 19s\n",
      "\tTrain Loss: 5.419 | Train PPL: 225.751\n",
      "\t Val. Loss: 6.167 |  Val. PPL: 476.525\n",
      "Epoch: 05 | Time: 130m 35s\n",
      "\tTrain Loss: 5.189 | Train PPL: 179.271\n",
      "\t Val. Loss: 6.124 |  Val. PPL: 456.819\n",
      "Epoch: 06 | Time: 131m 45s\n",
      "\tTrain Loss: 4.988 | Train PPL: 146.671\n",
      "\t Val. Loss: 6.107 |  Val. PPL: 449.047\n",
      "Epoch: 07 | Time: 135m 40s\n",
      "\tTrain Loss: 4.826 | Train PPL: 124.719\n",
      "\t Val. Loss: 6.114 |  Val. PPL: 451.926\n",
      "Epoch: 08 | Time: 135m 18s\n",
      "\tTrain Loss: 4.677 | Train PPL: 107.401\n",
      "\t Val. Loss: 6.132 |  Val. PPL: 460.434\n",
      "Epoch: 09 | Time: 137m 29s\n",
      "\tTrain Loss: 4.539 | Train PPL:  93.568\n",
      "\t Val. Loss: 6.166 |  Val. PPL: 476.264\n",
      "Epoch: 10 | Time: 133m 57s\n",
      "\tTrain Loss: 4.412 | Train PPL:  82.426\n",
      "\t Val. Loss: 6.204 |  Val. PPL: 494.548\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fddccd03-0fb0-4143-9e19-89a7cd0effda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역(translation) 함수\n",
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
    "    \"\"\"\n",
    "    문장을 받아 번역 해주는 함수.\n",
    "    \"\"\"\n",
    "    model.eval() # 평가 모드\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [text_ for text_ in tokenizer.morphs(sentence)][::-1]\n",
    "    else:\n",
    "        raise Exception(\"input 데이터가 str이 아닙니다.\")\n",
    "        \n",
    "\n",
    "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    print(f\"전체 소스 토큰: {tokens}\")\n",
    "\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    print(f\"소스 문장 인덱스: {src_indexes}\")\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "\n",
    "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        # 이전에 출력한 단어가 현재 단어로 입력될 수 있도록\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        # <eos>를 만나는 순간 끝\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
    "\n",
    "        \n",
    "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "\n",
    "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "33ce943c-da35-48d5-81b3-b04f7d1689d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<sos>', '?', '인가요', '무엇', '은', '저녁', '오늘', '<eos>']\n",
      "소스 문장 인덱스: [2, 43, 1373, 510, 12, 983, 220, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['today?']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '오늘 저녁은 무엇인가요?'\n",
    "\n",
    "translate_sentence(sentence, SRC, TRG, model, device, max_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44537c-0143-4072-bb7a-a928620785a3",
   "metadata": {},
   "source": [
    "# Reference\n",
    "---\n",
    "- https://codlingual.tistory.com/91"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdg",
   "language": "python",
   "name": "bdg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
