{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HIDDEN_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import Get_Dataset_and_Field\n",
    "train_iterator, valid_iterator, test_iterator, SRC, TRG = Get_Dataset_and_Field(data_size = 100000,batch_size = 256)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_iterator, \"val\": valid_iterator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "from utils.transformer import Encoder, Decoder, Transformer\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
    "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS,\n",
    "              ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS,\n",
    "              DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "\n",
    "# Transformer 객체 선언\n",
    "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기화\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW optimizer로 학습 최적화\n",
    "LEARNING_RATE = 0.0005\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    model.to(device)\n",
    "\n",
    "    # epoch시작\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 학습 모드로\n",
    "            else:\n",
    "                model.eval()   # 모델을 검증 모드로\n",
    "\n",
    "            epoch_loss = 0.0  # epoch loss 초기화\n",
    "\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "\n",
    "                src = batch.원문.to(device)  # input\n",
    "                trg = batch.번역문.to(device)  # output\n",
    "\n",
    "                # optimizer초기화\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파 계산\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
    "                    # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
    "                    output, _ = model(src, trg[:, :-1])\n",
    "                    # output: [배치 크기, trg_len - 1, output_dim]\n",
    "                    # trg: [배치 크기, trg_len]\n",
    "\n",
    "                    output_dim = output.shape[-1]\n",
    "                    output = output.contiguous().view(-1, output_dim)\n",
    "                    # 출력 단어의 인덱스 0(<sos>)은 제외\n",
    "                    trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "                    # output: [배치 크기 * trg_len - 1, output_dim]\n",
    "                    # trg: [배치 크기 * trg len - 1]\n",
    "\n",
    "                    # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "                    loss = criterion(output, trg)\n",
    "\n",
    "                    # 모델이 학습 모드일때 역전파 계산 및 파라미터 업데이트\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # epoch loss 더하기\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "            # epoch loss 계산\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                               phase, epoch_loss))\n",
    "\n",
    "            if phase == 'valid' and epoch_loss < best_loss:\n",
    "\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(),\n",
    "                           'transformer_korea_to_english.pt')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 \n",
    "num_epochs = 10\n",
    "model_trained = train_model(net, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
